{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle, resample\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def get_data(self, dtype={'isPaidContent': np.int8, 'pageTags': np.str}):\n",
    "        self.data = pd.read_csv(self.file_name, dtype=dtype)\n",
    "        return self.data\n",
    "\n",
    "    def process_data(self, data=None):\n",
    "        if data is None:\n",
    "            data = self.data\n",
    "        # Shuffeling the data\n",
    "        data = shuffle(data)\n",
    "\n",
    "        # Getting\n",
    "        X = data.pageTags\n",
    "        Y = data.isPaidContent\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            X, Y, test_size=0.15)\n",
    "\n",
    "        print('X.shape ', X_train.shape, ' Y.shape ', Y_train.shape,\n",
    "              ' x.shape ', X_test.shape, ' y.shape ', Y_test.shape)\n",
    "        return X_train, X_test, np.array(Y_train), np.array(Y_test)\n",
    "\n",
    "    @staticmethod\n",
    "    def resample_data(X, Y, type=None):\n",
    "        if type == 'SMOTE':\n",
    "            print('Resampling data : SMOTE...')\n",
    "\n",
    "            smote = SMOTE(ratio=1.0)\n",
    "            X_smote, Y_smote = smote.fit_sample(X, Y)\n",
    "\n",
    "            print('Data', X.shape, ' resampled to ', X_smote.shape)\n",
    "            return X_smote, Y_smote\n",
    "\n",
    "        elif type == 'RESAMPLE':\n",
    "            print('Resampling data : Up Sampling...')\n",
    "            # Postive data\n",
    "            pos = np.where(Y == 1)\n",
    "            pos_Y = Y[pos]\n",
    "            pos_X = X[pos]\n",
    "\n",
    "            # negative data\n",
    "            neg = np.where(Y == 0)\n",
    "            neg_Y = Y[neg]\n",
    "            neg_X = X[neg]\n",
    "\n",
    "            up_neg_X, up_neg_Y = resample(neg_X, neg_Y, n_samples=len(pos_Y))\n",
    "\n",
    "            print('Negative class data ', neg_X.shape, ' is UP Sampled to : ', up_neg_X.shape,\n",
    "                  ' as same positive class data ', pos_X.shape)\n",
    "\n",
    "            return np.r_[pos_X, up_neg_X], np.r_[pos_Y, up_neg_Y]\n",
    "        else:\n",
    "            print('Data is not Resampled, as type = SMOTE/RESAMPLE is not given ')\n",
    "            return X, Y\n",
    "\n",
    "\n",
    "class DataTokenizer():\n",
    "\n",
    "    def __init__(self, data, max_words=None, max_len=1000):\n",
    "        self.data = data\n",
    "        # oov_token=PorterStemmer\n",
    "        self.tokenizer = Tokenizer(\n",
    "            num_words=max_words, split=',')\n",
    "        self.tokenizer.fit_on_texts(self.data)\n",
    "        \n",
    "        self.input_dim = len(self.tokenizer.word_index)\n",
    "        self.input_len = max_len\n",
    "\n",
    "    def tokenize(self, data):\n",
    "        sequences = self.tokenizer.texts_to_sequences(data)\n",
    "        # print(sequences)\n",
    "        sequences_matrix = sequence.pad_sequences(\n",
    "            sequences, maxlen=self.input_len)\n",
    "        return sequences_matrix\n",
    "\n",
    "    def oneHotEncoding(self, data):\n",
    "        onehot = self.tokenizer.texts_to_matrix(data)\n",
    "        return onehot[:, 1:]\n",
    "\n",
    "    def tfidfEncoding(self, data):\n",
    "        tfidf = self.tokenizer.texts_to_matrix(data, mode='tfidf')\n",
    "        return tfidf[:, 1:]\n",
    "\n",
    "    def getVocabDim(self):\n",
    "        return self.input_dim, self.input_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_discrepancy(data, sortByKey = ['pageTags'], groupByKey = ['pageArticleID', 'pageTags']\n",
    "                     , indexLevel=['pageTags', 'pageArticleID', 'isPaidContent']):\n",
    "    \n",
    "    d = data.sort_values(by=sortByKey).groupby(groupByKey, sort=False, as_index=False) \\\n",
    "        .agg({'isPaidContent': pd.Series.nunique})\n",
    "    print('-----------------------------------------------------------------------------------------------------------\\n')\n",
    "    print('-------------- Duplicate Article ID and Page tag combination but different isPaidContent -----------------')\n",
    "    print(d[d.isPaidContent > 1].count().pageArticleID)\n",
    "    print('-----------------------------------------------------------------------------------------------------------\\n')\n",
    "    display(data[data.pageArticleID.isin(d[d.isPaidContent > 1].pageArticleID)].sort_values(by=['pageArticleID']).head(2))\n",
    "    print('-----------------------------------------------------------------------------------------------------------\\n')\n",
    "    print('-------------- Same Article ID is present more than 2 times -----------------')\n",
    "    print(data.pageArticleID.value_counts().head(5))\n",
    "    print('------------------------------------------------------\\n')\n",
    "    print('-------------- Max repeated article id -----------------\\n')\n",
    "    display(data[data.pageArticleID == d.pageArticleID[0]])\n",
    "\n",
    "    dp = data.sort_values(by=sortByKey).set_index(indexLevel)\n",
    "    print('\\n-------------- Duplicate pagetags/Article ID -----------------\\n')\n",
    "    display(dp.head(2))\n",
    "    print('-----------------------------------------------------------------------------------------------------------\\n')\n",
    "    print('-------------------------- Multindex value count --------------------------------------------------------')\n",
    "    print(dp.index.value_counts().head(1))\n",
    "    print('-------------------------- Total count of Article ID --------------------------------------------------------')\n",
    "    total_count = data.count().pageArticleID\n",
    "    print(total_count)\n",
    "    print('-------------- Count of Unique Article ID --------------------------------')\n",
    "    #print(dp[dp.index.get_level_values(level = 'pageArticleID').duplicated()])\n",
    "    unique_articles = dp.index.get_level_values(level = 'pageArticleID').nunique()\n",
    "    print(unique_articles)\n",
    "    print('-------------- Total Duplicate Article ID -----------------')\n",
    "    print( total_count -  unique_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def print_words(weight):\n",
    "    print('top keywords for separation')\n",
    "    print('-----------------------------')\n",
    "    w_dict = {}\n",
    "    for i in range(0, weight.shape[0]):\n",
    "        if weight[i] > 0:\n",
    "            w_dict[tok.tokenizer.index_word[i+1]] = weight[i]\n",
    "\n",
    "    for k in sorted(w_dict, key=w_dict.get, reverse=True):\n",
    "        print(k, float(w_dict[k]))\n",
    "\n",
    "\n",
    "def rms(y, y_hat):\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_hat))\n",
    "    print('Root Mean squre error is : ', rmse)\n",
    "    \n",
    "def metric_score(y, y_hat, type='Test'):\n",
    "    \n",
    "    tp = np.sum(np.logical_and(y == 1, y_hat == 1))\n",
    "    tn = np.sum(np.logical_and(y == 0, y_hat == 0))\n",
    "    fp = np.sum(np.logical_and(y == 0, y_hat == 1))\n",
    "    fn = np.sum(np.logical_and(y == 1, y_hat == 0))\n",
    "    \n",
    "    accuracy = np.divide(np.sum(tp + tn), np.sum(tp + tn + fp + fn))\n",
    "    precision = np.divide(tp,np.sum(tp + fp))\n",
    "    recall = np.divide(tp,np.sum(tp + fn))\n",
    "    f1 = f1_score(y, y_hat)\n",
    "    \n",
    "    print('\\n-----------', type ,'metric score------------------\\n')\n",
    "    print('True positives : ', tp)\n",
    "    print('True negatives : ', tn)\n",
    "    print('False positives : ', fp)\n",
    "    print('False negatives : ', fn)\n",
    "    print('precision : ', precision)\n",
    "    print('recall : ', recall)\n",
    "    print('Accuracy : ', accuracy)\n",
    "    print('f1 Score : ', f1)\n",
    "    print('\\n------------------------------------------\\n')\n",
    "    \n",
    "    df = pd.DataFrame({ type : {'true-postive' : tp,\n",
    "                        'true-negative' : tn,\n",
    "                        'false-positive' : fp,\n",
    "                        'false-negative' : fn,\n",
    "                        'accuracy' : accuracy,\n",
    "                        'precision' : precision,\n",
    "                        'recall' : recall,\n",
    "                        'f1 Score' : f1}})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import functools\n",
    "\n",
    "def provide_progress_bar(function, estimated_time, tstep=0.2, tqdm_kwargs={}, args=[], kwargs={}):\n",
    "    \"\"\"Tqdm wrapper for a long-running function\n",
    "\n",
    "    args:\n",
    "        function - function to run\n",
    "        estimated_time - how long you expect the function to take\n",
    "        tstep - time delta (seconds) for progress bar updates\n",
    "        tqdm_kwargs - kwargs to construct the progress bar\n",
    "        args - args to pass to the function\n",
    "        kwargs - keyword args to pass to the function\n",
    "    ret:\n",
    "        function(*args, **kwargs)\n",
    "    \"\"\"\n",
    "    ret = [None]  # Mutable var so the function can store its return value\n",
    "    def myrunner(function, ret, *args, **kwargs):\n",
    "        ret[0] = function(*args, **kwargs)\n",
    "\n",
    "    thread = threading.Thread(target=myrunner, args=(function, ret) + tuple(args), kwargs=kwargs)\n",
    "    pbar = tqdm(total=estimated_time, **tqdm_kwargs)\n",
    "\n",
    "    thread.start()\n",
    "    while thread.is_alive():\n",
    "        thread.join(timeout=tstep)\n",
    "        pbar.update(tstep)\n",
    "    pbar.close()\n",
    "    return ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = 'Results'\n",
    "\n",
    "\n",
    "def save_results_csv(filename, data, mode=None):\n",
    "    f = '{}/{}.csv'.format(result_folder, filename)\n",
    "    if mode is None:\n",
    "        data.to_csv(f)\n",
    "    else:\n",
    "        data.to_csv(f, mode=mode)\n",
    "\n",
    "def save_results_html(filename, data):\n",
    "    f = '{}/{}.html'.format(result_folder, filename)\n",
    "    #Ploting\n",
    "    plot_metric(data, f)\n",
    "    data.to_html(f, col_space=15)\n",
    "    \n",
    "def plot_metric(data, filename):\n",
    "    \n",
    "    df_plot = pd.concat([data['Score']['Training'], data['Score']['Test']], axis=1)\n",
    "    df_plot['metric'] = df_plot.index\n",
    "    df_plot = df_plot[(df_plot['metric'] == 'precision') | (df_plot['metric'] == 'recall') | (df_plot['metric'] == 'accuracy') | (df_plot['metric'] == 'f1 Score')]\n",
    "\n",
    "    ax = df_plot.plot(kind='bar',x='metric',y=['Training','Test'], color=['blue', 'red'], figsize=(20,7.5))\n",
    "    ax.set_title('best model')\n",
    "    \n",
    "    x_length = 0\n",
    "    for i, r in df_plot.iterrows():\n",
    "        ax.text(x=x_length - 0.20, y=r['Training'] + 0.01,  s = \"{0:.3f}\".format(r['Training']), color='blue', fontweight='bold')\n",
    "        ax.text(x=x_length + 0.1, y=r['Test'] + 0.01,  s = \"{0:.3f}\".format(r['Test']), color='red', fontweight='bold')\n",
    "        x_length = x_length + 1\n",
    "    \n",
    "    df_model = data['Model']['best_params']\n",
    "    title = df_model[df_model.index == 'model']\n",
    "    \n",
    "    ax.set_title('Best Model : {}'.format(title.values))\n",
    "    \n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig(filename.replace('html', 'png'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def plot_boundary(X, Y, model, filename=None, h=0.1):\n",
    "    # create a mesh to plot in\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    x1, x2 = np.meshgrid(np.arange(x1_min, x1_max, h),\n",
    "                         np.arange(x2_min, x2_max, h))\n",
    "    #print(x1.shape, x2.shape)\n",
    "\n",
    "    Z = np.zeros(x1.shape)\n",
    "    print(Z.shape)\n",
    "    for i in tqdm(range(0, x1.shape[1])):\n",
    "        X_ = np.c_[x1[:, i].ravel(), x2[:, i].ravel()]\n",
    "        yy= model.predict(X_)\n",
    "        \n",
    "        if yy.ndim == 2:\n",
    "            yy = yy.reshape(x1.shape[0])\n",
    "            \n",
    "        Z[:, i] = yy\n",
    "\n",
    "    #print(xx.shape, yy.shape, Z)\n",
    "    # Put the result into a color plot\n",
    "    fig = plt.figure(figsize=(20, 5))\n",
    "    plt.ion()\n",
    "    plt.contour(x1, x2, Z, cmap=plt.cm.coolwarm, alpha=1)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.coolwarm)\n",
    "    plt.xlim(x1.min(), x1.max())\n",
    "    plt.ylim(x2.min(), x2.max())\n",
    "    \n",
    "    if filename is not None:\n",
    "        file = '{}/{}-boundary.png'.format(result_folder, filename)\n",
    "        fig.savefig(file)\n",
    "        \n",
    "    plt.draw()\n",
    "\n",
    "# pause = False\n",
    "\n",
    "# def onClick(event):\n",
    "#     global pause\n",
    "#     pause ^= True\n",
    "    \n",
    "# Animated class to draw score.\n",
    "class AnimateScores():\n",
    "    \n",
    "    def __init__(self, iterations):\n",
    "        \n",
    "        self.itr = iterations\n",
    "        \n",
    "        fig = plt.figure(figsize=(20, 5))\n",
    "        \n",
    "        ax = plt.axes(xlim=(0, iterations+1))\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_xlabel('Iterations')\n",
    "        \n",
    "        self.fig = fig\n",
    "        self.plt = plt\n",
    "        self.ax = ax\n",
    "        \n",
    "        tl,  = self.plt.plot([],[], color='blue', marker='o', label='Training Score')\n",
    "        vl,  = self.plt.plot([],[], color='red', marker='+', label='Validation Score')\n",
    "        \n",
    "        ax.legend(shadow=True, fontsize='x-large')\n",
    "        \n",
    "        #self.plt.ion()\n",
    "        self.tl = tl\n",
    "        self.vl = vl\n",
    "        \n",
    "        self.training_scores = []\n",
    "        self.validation_scores = []\n",
    "        self.counts = []\n",
    "\n",
    "        \n",
    "    def plotScores(self,training_scores, validation_scores):\n",
    "        self.anim = animation.FuncAnimation(self.fig, self.update_line, \n",
    "                                       frames=range(0, self.itr),\n",
    "                                       fargs=(training_scores, validation_scores),\n",
    "                                       interval=self.itr**2, blit=True, init_func=self.init, repeat=True)\n",
    "        \n",
    "        \n",
    "    def plotScoresRealtime(self,frames):\n",
    "#         self.fig.canvas.mpl_connect('button_press_event', onClick)\n",
    "        self.anim = animation.FuncAnimation(self.fig, self.update_line_realtime, \n",
    "                                       frames=frames,\n",
    "                                       blit=True, init_func=self.init, repeat=True)\n",
    "        \n",
    "        self.plt.pause(self.itr)\n",
    "#         self.plt.close()\n",
    "#         self.plt.show(block=True)\n",
    "        \n",
    "\n",
    "    def init(self):\n",
    "        self.tl.set_data([], [])\n",
    "        self.vl.set_data([], [])\n",
    "        return self.tl,self.vl,\n",
    "    \n",
    "    def update_line(self, num, tScore, vScore):\n",
    "        self.tl.set_data(tScore[::, :num])\n",
    "        self.vl.set_data(vScore[::, :num])\n",
    "        return self.tl,self.vl,\n",
    "\n",
    "    def update_line_realtime(self, frame):\n",
    "        self.training_scores.append(frame[0])\n",
    "        self.validation_scores.append(frame[1])\n",
    "        self.counts.append(frame[2])\n",
    "        \n",
    "        self.tl.set_data(self.counts, self.training_scores)\n",
    "        self.vl.set_data(self.counts, self.validation_scores)\n",
    "        return self.tl,self.vl,\n",
    "    \n",
    "    def save(self, filename=None):\n",
    "        if filename is not None:\n",
    "            f = '{}/{}.gif'.format(result_folder, filename)\n",
    "            print(\".... Saving aimation {}\".format(f))\n",
    "            self.anim.save(f, writer = \"pillow\", fps=5) \n",
    "    \n",
    "#Static graph to plot scores\n",
    "def plot_scores(iterations, training_scores, validation_scores, file = None):\n",
    "    \n",
    "        fig = plt.figure(figsize=(20, 5))\n",
    "        ax = plt.axes(xlim=(0, iterations + 1))\n",
    "    \n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_xlabel('Iterations')\n",
    "    \n",
    "        plt.plot(range(1, iterations+1),training_scores, color='blue', marker='o', label='Training Score')\n",
    "        plt.plot(range(1, iterations+1),validation_scores, color='red', marker='+', label='Validation Score')\n",
    "\n",
    "        ax.legend(shadow=True, fontsize='x-large')\n",
    "        \n",
    "        if file is not None:\n",
    "            f = '{}/{}.png'.format(result_folder, file)\n",
    "            fig.savefig(f)\n",
    "        \n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "128px",
    "width": "265px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
