{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.kernel_approximation import RBFSampler, Nystroem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online SVM classifier is for training data in mini batches or strems.\n",
    "class OnlineSVMClassifier():\n",
    "    \n",
    "    def __init__(self, loss='hinge', penalty='l2', alpha=0.0001, verbose=1):\n",
    "        self.model = SGDClassifier(loss=loss, penalty=penalty, alpha=alpha, verbose=verbose)\n",
    "    \n",
    "    def partial_fit_realitime(self, X, Y, batch_size=None, max_itr = 100, W=None):\n",
    "        \n",
    "        old_val_score = 0 \n",
    "        old_tr_score = 0 \n",
    "        \n",
    "        kf = KFold(n_splits=max_itr)\n",
    "        X, Y = shuffle(X, Y)\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        for train_index, test_index in kf.split(X):\n",
    "            count = count + 1\n",
    "            \n",
    "            X_train, X_valid = X[train_index], X[test_index]\n",
    "            Y_train, Y_valid = Y[train_index], Y[test_index]\n",
    "            \n",
    "            t = 0\n",
    "            \n",
    "            if batch_size is not None:\n",
    "                pbar = tqdm(range(0, X_train.shape[0], batch_size))\n",
    "                for i in pbar:\n",
    "                    self.model.partial_fit(X_train[i:(i+batch_size)], Y_train[i:(i+batch_size)],classes=[0, 1] ,sample_weight=W)\n",
    "                    t = t + self.score(X_train[i:(i+batch_size)], Y_train[i:(i+batch_size)])\n",
    "\n",
    "                    pbar.set_description(\"Iteration %d\" % count)\n",
    "\n",
    "                tr_score = t/(X_train.shape[0]/batch_size)\n",
    "            else:\n",
    "                self.model.fit(X_train, Y_train ,sample_weight=W)\n",
    "                tr_score = self.score(X_train, Y_train)\n",
    "                \n",
    "            val_score = self.score(X_valid, Y_valid)\n",
    "            \n",
    "            old_tr_score = tr_score\n",
    "            old_val_score = val_score\n",
    "            \n",
    "            yield tr_score, val_score, count\n",
    "        \n",
    "    def partial_fit(self, X, Y, batch_size=None, max_itr = 100, W=None, anim=None):\n",
    "        \n",
    "        old_val_score = 0 \n",
    "        old_tr_score = 0 \n",
    "        \n",
    "        kf = KFold(n_splits=max_itr)\n",
    "        X, Y = shuffle(X, Y)\n",
    "        \n",
    "        counts = []\n",
    "        count = 0\n",
    "        \n",
    "        training_scores = []\n",
    "        validation_scores = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X):\n",
    "            count = count + 1\n",
    "            \n",
    "            X_train, X_valid = X[train_index], X[test_index]\n",
    "            Y_train, Y_valid = Y[train_index], Y[test_index]\n",
    "            \n",
    "            t = 0\n",
    "            \n",
    "            if batch_size is not None:\n",
    "                pbar = tqdm(range(0, X_train.shape[0], batch_size))\n",
    "                for i in pbar:\n",
    "                    self.model.partial_fit(X_train[i:(i+batch_size)], Y_train[i:(i+batch_size)],classes=[0, 1] ,sample_weight=W)\n",
    "                    t = t + self.score(X_train[i:(i+batch_size)], Y_train[i:(i+batch_size)])\n",
    "\n",
    "                    pbar.set_description(\"Iteration %d\" % count)\n",
    "\n",
    "                tr_score = t/(X_train.shape[0]/batch_size)\n",
    "            else:\n",
    "                self.model.fit(X_train, Y_train ,sample_weight=W)\n",
    "                tr_score = self.score(X_train, Y_train)\n",
    "                \n",
    "            val_score = self.score(X_valid, Y_valid)\n",
    "            \n",
    "            #             print('tr_score : ' , tr_score , ' val_score :',  val_score)\n",
    "#             print('diff : ' , tr_score - val_score)\n",
    "#             if tr_score < old_tr_score and val_score < old_val_score :\n",
    "#                 break\n",
    "            \n",
    "            old_tr_score = tr_score\n",
    "            old_val_score = val_score\n",
    "            \n",
    "            # Plotting\n",
    "            counts.append(count)\n",
    "            training_scores.append(tr_score)\n",
    "            validation_scores.append(val_score)\n",
    "            \n",
    "            if anim is not None:\n",
    "                anim.plotScores(np.vstack([np.array(counts), np.array(training_scores)]), np.vstack([np.array(counts), np.array(validation_scores)]))\n",
    "                \n",
    "        return training_scores, validation_scores\n",
    "            \n",
    "    def fit(self, X, Y, W=None):\n",
    "        self.model.fit(X, Y, sample_weight=W)\n",
    "        print('SVM training done-----')\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def score(self, x, y, w=None):\n",
    "        score = self.model.score(x, y, sample_weight=w)\n",
    "        return score\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return self.model.get_params(deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Online_SVM_model(X_matrix, Y, x_matrix, y, kernel=None , batch_size = None , loss='hinge', penalty='l2', alpha=0.0001, max_itr = 100 ,verbose=1, plot=False, words=False, \n",
    "                     filename = None, animate=False):\n",
    "\n",
    "    if kernel == 'rbf':\n",
    "        print('RBF kernel...')\n",
    "        X_features, x_features = RBFKernel(X_matrix, x_matrix)\n",
    "    else:\n",
    "        print('Linear kernel...')\n",
    "        X_features, x_features = X_matrix, x_matrix\n",
    "    \n",
    "    print(X_features.shape, x_features.shape)\n",
    "    online_svm = OnlineSVMClassifier(loss=loss, penalty=penalty, alpha=alpha, verbose=verbose)\n",
    "    \n",
    "    # Animate the plots\n",
    "    anim = AnimateScores(max_itr)\n",
    "    if animate:\n",
    "        anim.plotScoresRealtime(frames = online_svm.partial_fit_realitime(X_features, Y, batch_size, max_itr = max_itr))\n",
    "    else:\n",
    "        training_scores, validation_scores = online_svm.partial_fit(X_features, Y, batch_size, max_itr = max_itr, anim=anim)\n",
    "        anim.save(filename = filename + \"-Animation-score\")\n",
    "        # Plot static score\n",
    "        plot_scores(max_itr, training_scores, validation_scores, file=filename + \"-score\")\n",
    "        \n",
    "    \n",
    "    if plot:\n",
    "        plot_boundary(X_matrix, Y, svm, filename = filename, h=1)\n",
    "    \n",
    "    print('\\n----------------------------Parameters---------------------------------------------\\n')\n",
    "    training_score = online_svm.score(X_features, Y)\n",
    "    print('Trainign Accuracy score : ', training_score)\n",
    "    print('\\n------------------------------------------------------------------------------------\\n')\n",
    "          \n",
    "    y_trainig_hat = online_svm.predict(X_features)\n",
    "#     print('precision score ', precision_score(Y, y_trainig_hat))\n",
    "#     print('\\n------------------------------------------------------------------------------------\\n')\n",
    "#     print('f1 score ', f1_score(Y, y_trainig_hat))\n",
    "    \n",
    "    train_metric = metric_score(Y, y_trainig_hat, type='Training')\n",
    "\n",
    "    test_score = online_svm.score(x_features, y)\n",
    "    print('Test Accuracy score : ', test_score)\n",
    "    print('\\n------------------------------------------------------------------------------------\\n')\n",
    "          \n",
    "    y_test_hat = online_svm.predict(x_features)\n",
    "#     print('precision score ', precision_score(y, y_test_hat))\n",
    "#     print('\\n------------------------------------------------------------------------------------\\n')\n",
    "#     print('f1 score ', f1_score(y, y_test_hat))\n",
    "    \n",
    "    test_metric = metric_score(y, y_test_hat, type='Test')\n",
    "\n",
    "    if filename is not None:\n",
    "        pd_best = pd.DataFrame({\"best_params\" : {'model': online_svm.model, 'model__alpha': alpha}})\n",
    "        save_results_html(filename, pd.concat([pd.concat([train_metric, test_metric], axis=1, sort=False), pd_best], keys=['Score', 'Model'], axis=1, sort=False))\n",
    "    \n",
    "    if words:\n",
    "        print('------- Top words ---------')\n",
    "        print_words(online_svm.model.coef_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBFKernel(X_matrix, x_matrix):\n",
    "    \n",
    "    m  = X_matrix.shape[1]\n",
    "    \n",
    "    rbf_feature = Nystroem(gamma=1/m , random_state=1, n_components=m)\n",
    "    X_features = rbf_feature.fit_transform(X_matrix)\n",
    "    \n",
    "    x_features = rbf_feature.transform(x_matrix)\n",
    "    \n",
    "    return X_features, x_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
