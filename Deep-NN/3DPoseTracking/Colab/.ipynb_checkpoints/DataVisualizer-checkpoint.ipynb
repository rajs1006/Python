{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.cm import jet\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.spatial.transform import Rotation\n",
    "from scipy.stats import norm\n",
    "\n",
    "from numpy import linalg as lin\n",
    "import cv2 \n",
    "\n",
    "from skimage import exposure, io\n",
    "from skimage.exposure import match_histograms\n",
    "import shutil\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "#path = \"/home/sourabh/Documents/GIT/Python/Deep-NN/PoseTracking/minion\"\n",
    "path = \"/home/sourabh/Documents/GIT/Python/Deep-NN/PoseTracking/Real/Buffalo/1000/captures_buffalo_1000_sift\"\n",
    "dataPath = \"captures\"\n",
    "\n",
    "width, height = 640, 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/Conda/conda/lib/python3.7/site-packages/statsmodels/nonparametric/kde.py:487: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "/opt/Conda/conda/lib/python3.7/site-packages/statsmodels/nonparametric/kdetools.py:34: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'ravel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1fd35e0ff96f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mvisualizeData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Real'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'ravel'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualizeData(images, title = \" \", label=\"\"):\n",
    "    ax = sns.distplot(images, label='{}'.format(label), kde=True);\n",
    "    ax.set_title(title)\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "file = 'image_%05d_img'\n",
    "n = 50\n",
    "\n",
    "t = []\n",
    "for i in range(n):\n",
    "    \n",
    "    f = file %i + '.png'\n",
    "    \n",
    "    image_folder = os.path.join(path, 'captures',  'R')\n",
    "    img =  cv2.imread(os.path.join(image_folder, f), 0)\n",
    "    hist = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "    \n",
    "    visualizeData(hist, title='Real', label=f)\n",
    "    t.append(img.ravel())\n",
    "\n",
    "plt.show()\n",
    "plt.hist(t,256,[0,256]); plt.show()\n",
    "\n",
    "\n",
    "t = []\n",
    "for i in range(n):\n",
    "    \n",
    "    f = file %i + '.png'\n",
    "    image_folder = os.path.join(path, 'captures',  'SynthTest')\n",
    "    img =  cv2.imread(os.path.join(image_folder, f), 0)\n",
    "    hist = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "    visualizeData(hist,title='Synth', label=f)\n",
    "    t.append(img.ravel())\n",
    "    \n",
    "plt.show()\n",
    "plt.hist(t,256,[0,256]); plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'image_%05d_img'\n",
    "n= 100\n",
    "\n",
    "image_folder = os.path.join(path, 'captures')\n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    f = file %i + '.png'\n",
    "    \n",
    "    sourceImagePath = os.path.join(image_folder,  'R')\n",
    "    destImagePath = os.path.join(image_folder,  'SynthTest')\n",
    "    \n",
    "    sourceImage = os.path.join(sourceImagePath, f)\n",
    "    destImage = os.path.join(destImagePath, f)\n",
    "    \n",
    "    matchedImage = match_histograms(cv2.imread(sourceImage), cv2.imread(destImage), multichannel=True)\n",
    "    \n",
    "    #.imshow(matchedImage)\n",
    "    io.imsave(os.path.join(sourceImagePath, f), matchedImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawKeyPoints(dataSet, count,plot=True):\n",
    "    \n",
    "    # define the size of images\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "    plt.ion()\n",
    "    # randomly select a sample\n",
    "    sample = dataSet\n",
    "\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    ax.set_title('Sample #{}'.format(count))\n",
    "\n",
    "    # Using the same display function, defined earlier\n",
    "    show_keypoints(sample['image'], sample['keypoints'], sample['bound'], ax, plot=plot)\n",
    "        \n",
    "def show_keypoints(image, key_pts, bound, ax, plot=True):\n",
    "    \"\"\"Show image with keypoints\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.gca().add_patch(patches.Rectangle((bound[0]),bound[1][0],bound[1][1],fill=False, linewidth=1,edgecolor='b')) \n",
    "    \n",
    "    for i, k in enumerate(key_pts):\n",
    "        plt.scatter(k[0], k[1], s=20, marker='+', c='m')\n",
    "        ax.annotate(i, xy=(k[0], k[1]), arrowprops=None)\n",
    "        \n",
    "    #plt.scatter(key_pts[:, 0], (key_pts[:, 1]), s=20, marker='+', c='m')\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(key_pts[:, 0], key_pts[:, 1], c='m', label='Predicted')\n",
    "        \n",
    "def plot_mesh(faces, verts, img, R, t, cameraMatrix, filename = None):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    verts_2d = np.matmul(cameraMatrix, np.matmul(R, verts.T) + t).T\n",
    "    verts_2d = verts_2d[:,:2] / verts_2d[:,2, None]\n",
    "    #verts_2d[:, 1] = 480 - verts_2d[:, 1]\n",
    "    \n",
    "    patches = []\n",
    "    for face in faces:\n",
    "        points = [verts_2d[i_vertex-1] for i_vertex in face]\n",
    "        #print(points)\n",
    "        poly = Polygon(points, True)\n",
    "        patches.append(poly)\n",
    "        \n",
    "    p = PatchCollection(patches, cmap=matplotlib.cm.jet, alpha=0.3)\n",
    "    ax.add_collection(p)\n",
    "    \n",
    "    if filename is not None:\n",
    "        plt.savefig(\"{}/{}_{}\".format(image_folder, 'mesh' ,filename))\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizeData():\n",
    "    \n",
    "    def __init__(self, file=\"image_%05d_img\", saveFig = False):\n",
    "        self.saveFig = saveFig\n",
    "        self.folderPath = os.path.join(path, dataPath)\n",
    "        self.file = file\n",
    "        \n",
    "    def drawGroundTruth(self):\n",
    "        self.drawData(\"GroundTruth/\", \"image_groundtruth_img\", count=1, groundTruth=True, plot = True, saveFig=self.saveFig);\n",
    "        \n",
    "    def drawImages(self, real=False, num=5):\n",
    "        for i in range(0, num):\n",
    "            if not real:\n",
    "                self.drawData(\"Train/\", self.file %i, count = i, plot = True, saveFig=self.saveFig)\n",
    "            else:\n",
    "                self.drawData(\"RealTest/\", self.file %i, count = i, real=True, plot = True, saveFig=self.saveFig)\n",
    "                \n",
    "    def drawMesh(self, real=False, num=5, PnP=False):\n",
    "        if not real:\n",
    "            print('Drawing Synthetic data')\n",
    "            folder=\"Train/\" \n",
    "        else:\n",
    "            print('Drawing Real data')\n",
    "            folder=\"RealTest/\" \n",
    "        \n",
    "        for i in range(0, num):\n",
    "            self.verifySynthImages(folder = folder,file = self.file %i, real = real, PnP=PnP)\n",
    "            \n",
    "    def verifySynthImages(self, folder, file ,real=False, PnP = False):\n",
    "        \n",
    "        folderPath = os.path.join(self.folderPath, folder)\n",
    "        \n",
    "        point3D = pd.read_csv(os.path.join(self.folderPath, \"GroundTruth/image_groundtruth_img-3DGT.txt\"), header=None, sep=',').to_numpy().astype(float)\n",
    "        vertices = pd.read_csv(os.path.join(self.folderPath, \"GroundTruth/image_groundtruth_img-3DVertices.txt\"), header=None, sep=',').to_numpy().astype(float) \n",
    "        faces = pd.read_csv(os.path.join(self.folderPath, \"GroundTruth/image_groundtruth_img-3DFaces.txt\"), header=None, sep=',').to_numpy().astype(int)\n",
    "        \n",
    "        img  = imageio.imread(os.path.join(folderPath, \"{}.png\".format(file)))\n",
    "        \n",
    "        if not real:\n",
    "            cameraMatrix = pd.read_csv(os.path.join(self.folderPath, \"GroundTruth/CameraMatrix.txt\"), header=None, sep=',').to_numpy().astype(float)\n",
    "            point2d = np.array(pd.read_csv(os.path.join(folderPath, \"{}-GT.txt\".format(file)), header=None))\n",
    "        else:\n",
    "            cameraMatrix = pd.read_csv(os.path.join(folderPath, \"{}-Camera.txt\".format(file)), header=None, sep=' ').to_numpy().astype(float)\n",
    "            cameraMatrix = cameraMatrix.reshape((3, 3))\n",
    "#             GTPointsInit = np.matmul(cameraMatrix, np.matmul(rot, np.squeeze(point3D).T) + trans).T\n",
    "#             point2d1 = GTPointsInit[:,:2] / GTPointsInit[:,2, None]\n",
    "            point2d = pd.read_csv(os.path.join(folderPath, \"{}-GT.txt\".format(file)), header=None, sep=' ').to_numpy().astype(float)\n",
    "            \n",
    "        if PnP:\n",
    "            print('Performing PnP')\n",
    "            ret, rvecs, tvecs = cv2.solvePnP(point3D,\\\n",
    "                                     point2d,\\\n",
    "                                     cameraMatrix,\\\n",
    "                                     np.zeros((1,5)), flags = 0)\n",
    "    \n",
    "            rot, part_jacob = cv2.Rodrigues(rvecs)\n",
    "            trans = tvecs\n",
    "        else:\n",
    "            rot = np.array(pd.read_csv(os.path.join(folderPath, \"{}-Rot.txt\".format(file)), header=None, sep=' ')).reshape((3, 3))\n",
    "            trans =  np.array(pd.read_csv(os.path.join(folderPath, \"{}-Trans.txt\".format(file)), header=None, sep=' ')).reshape((3,1))\n",
    "            \n",
    "        plot_mesh(faces, vertices, img, rot, trans, cameraMatrix)\n",
    "        \n",
    "    def drawData(self, folder, file, count, real = False, groundTruth=False, plot = False, saveFig=True):\n",
    "        \n",
    "        folderPath = os.path.join(self.folderPath, folder)\n",
    "    \n",
    "        img  = imageio.imread(os.path.join(folderPath, \"{}.png\".format(file)))\n",
    "\n",
    "        sep = ':' if groundTruth else ','\n",
    "\n",
    "        ## This gives Height and Width\n",
    "        if not real:\n",
    "            \n",
    "            dataGT = pd.read_csv(os.path.join(folderPath, \"{}-GT.txt\".format(file)), header=None, sep=sep)\n",
    "            dataBound = np.array(pd.read_csv(os.path.join(folderPath, \"{}-BOUND.txt\".format(file)), header=None))\n",
    "            dataBound[1] = dataBound[1] - dataBound[0]\n",
    "        else:\n",
    "            dataGT = pd.read_csv(os.path.join(folderPath, \"{}-GT.txt\".format(file)), header=None, sep=' ')\n",
    "            dataBound = np.array(pd.read_csv(os.path.join(folderPath, \"{}-BOUND.txt\".format(file)), header=None, sep=' ')).reshape((2, 2))\n",
    "            #print(dataBound)\n",
    "            #dataBound[1] = dataBound[1] + dataBound[0]\n",
    "            \n",
    "        if groundTruth:\n",
    "            d = dataGT[0].str.strip(to_strip='( )')\n",
    "            groundTruthKPs = np.array([i for i in d.str.split(',')], dtype=float);\n",
    "            groundTruthKPs[:, 1] = height - groundTruthKPs[: , 1]\n",
    "\n",
    "            dataSet = {'image' : img, 'keypoints' : groundTruthKPs, 'bound' : dataBound}\n",
    "        else:\n",
    "            dataGT = np.asarray(dataGT)\n",
    "#             print(dataGT.shape)\n",
    "            #dataGT[:, 1] = dataGT[: , 1] - 150\n",
    "            dataSet = {'image' : img,'keypoints' : dataGT, 'bound' : dataBound }\n",
    "\n",
    "        drawKeyPoints(dataSet, count = count, plot = plot)\n",
    "\n",
    "        if saveFig:\n",
    "            plt.savefig(os.path.join(folderPath, \"{}-gt.png\".format(file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"/home/sourabh/Documents/TU-Berlin/Thesis/Sytheticdata/ml-imagesynthesis/\"\n",
    "path = \"/home/sourabh/Documents/GIT/Python/Deep-NN/PoseTracking/Real/Buffalo/1000/captures_buffalo_1000_random\"\n",
    "vis = VisualizeData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vis.drawGroundTruth()\n",
    "#vis.drawImages(real=True, num=70)\n",
    "#vis.drawMesh(real=True, num=5, PnP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Reprojected 3D points which are correctly ptojected and so th emesh is correct : START\n",
    "\n",
    "#             predictedPoints = torch.cat((output_pts.type(torch.FloatTensor), torch.ones(GTPoints.shape[0],1, device=GTPoints.device)), dim=-1).t()\n",
    "#             points3Dreprojected = np.matmul(gdRot.inverse().detach().cpu().numpy(), \\\n",
    "#                                    (np.matmul(cameraMatrix.inverse().detach().cpu().numpy(), predictedPoints.detach().cpu().numpy()) \\\n",
    "#                                     - gdTrans.detach().cpu().numpy())).T\n",
    "\n",
    "#             rot1,dst = cv2.Rodrigues(gdRot.detach().cpu().numpy())\n",
    "#             print('GT 2D points : ', cv2.projectPoints(point3D,rot1, gdTrans.detach().cpu().numpy(), cameraMatrix.detach().cpu().numpy(), 1.0))\n",
    "\n",
    "#             point3D = points3Dreprojected\n",
    "            #### Reprojected 3D points which are correctly ptojected and so th emesh is correct : END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory(path, directory = 'captures' ,folder=\"Train/\", file=\"image_%05d%s\" ,num=200):\n",
    "    \n",
    "    position = []\n",
    "    translation = []\n",
    "    \n",
    "    for i in range(num):\n",
    "        pos = pd.read_csv(os.path.join(path, directory, folder, file %(i, '_camera_pos.txt')), header=None, sep=\",\")\n",
    "        pos[0] = pos[0].str.strip(to_strip='( )').astype(np.float)\n",
    "        pos[2] = pos[2].str.strip(to_strip='( )').astype(np.float)\n",
    "\n",
    "        position.append(np.array(pos))\n",
    "                          \n",
    "        trans = pd.read_csv(os.path.join(path, directory, folder, file %(i, '_img-Trans.txt')), header=None, sep=\" \")\n",
    "        translation.append(np.array(trans))\n",
    "                          \n",
    "    position = np.squeeze(np.asarray(position))\n",
    "    translation = np.squeeze(np.array(translation))\n",
    "    print(position.shape, translation.shape)\n",
    "                          \n",
    "    return position, translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3) (200, 3)\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/sourabh/Documents/TU-Berlin/Thesis/Sytheticdata/ml-imagesynthesis/\"\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "pos, trans = trajectory(path)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(trans[:, 0], trans[:, 1], trans[:, 2], marker='o')\n",
    "# plt.show()\n",
    "\n",
    "data = []\n",
    "\n",
    "data.append(go.Scatter3d(x=pos[:, 0], y=pos[:, 1], z=pos[:, 2], name='Camera trajectory', \\\n",
    "                         mode='markers', marker_color='red', marker_size=1.5))\n",
    "\n",
    "data.append(go.Scatter3d(x=trans[:, 0], y=trans[:, 1], z=trans[:, 2], name='Object position',\\\n",
    "                         mode='markers', marker_color='blue', marker_size=1))\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "#fig.update_traces(mode='markers', marker_line_width=5, marker_size=0.2)\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1,\n",
    "        traceorder=\"normal\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.write_image('trajectory_3D_2.png')\n",
    "\n",
    "#print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
